{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(i) for i in range(2015,2023)]\n",
    "columns = [0,3,5,6,8,9,10,32,60,101,102,103,104,105,108,111,114,117,120,123,\\\n",
    "           126,129,132,135,138,141,144,147,150,153,156]\n",
    "column_names = ['Date','Visiting Team','Visiting Team G#','Home Team', \\\n",
    "                'Home Team G#','Away Score','Home Score','SO (Away)', \\\n",
    "                'SO (Home)','SP ID (Away)','SP Name (Away)','SP ID (Home)', \\\n",
    "                'SP Name (Home)','P1 ID (Away)','P2 ID (Away)','P3 ID (Away)', \\\n",
    "                'P4 ID (Away)','P5 ID (Away)','P6 ID (Away)','P7 ID (Away)', \\\n",
    "                'P8 ID (Away)','P9 ID (Away)','P1 ID (Home)','P2 ID (Home)', \\\n",
    "                'P3 ID (Home)','P4 ID (Home)','P5 ID (Home)','P6 ID (Home)', \\\n",
    "                'P7 ID (Home)','P8 ID (Home)','P9 ID (Home)']\n",
    "\n",
    "lineup_column_names = [ \n",
    "    'Unnamed: 0',\n",
    "    'IDfg',\n",
    "    'Name',\n",
    "    'Age',\n",
    "    'PA',\n",
    "    'AVG',\n",
    "    'BB%',\n",
    "    'K%',\n",
    "    'BB/K',\n",
    "    'OBP',\n",
    "    'SLG',\n",
    "    'Spd',\n",
    "    'wRAA',\n",
    "    'wFB/C',\n",
    "    'wSL/C',\n",
    "    'wCT/C',\n",
    "    'wCB/C',\n",
    "    'wCH/C',\n",
    "    'wSF/C',\n",
    "    'wKN/C',\n",
    "    'O-Swing%',\n",
    "    'Z-Swing%',\n",
    "    'Swing%',\n",
    "    'O-Contact%',\n",
    "    'Z-Contact%',\n",
    "    'Contact%',\n",
    "    'Zone%',\n",
    "    'F-Strike%',\n",
    "    'SwStr%',\n",
    "]\n",
    "\n",
    "lineup_column_names_trimmed = [\n",
    "    'AVG',\n",
    "    'BB%',\n",
    "    'K%',\n",
    "    'BB/K',\n",
    "    'OBP',\n",
    "    'SLG',\n",
    "    'Spd',\n",
    "    'wRAA',\n",
    "    'wFB/C',\n",
    "    'wSL/C',\n",
    "    'wCT/C',\n",
    "    'wCB/C',\n",
    "    'wCH/C',\n",
    "    'wSF/C',\n",
    "    'wKN/C',\n",
    "    'O-Swing%',\n",
    "    'Z-Swing%',\n",
    "    'Swing%',\n",
    "    'O-Contact%',\n",
    "    'Z-Contact%',\n",
    "    'Contact%',\n",
    "    'Zone%',\n",
    "    'F-Strike%',\n",
    "    'SwStr%',\n",
    "]\n",
    "\n",
    "pitching_column_names = [\n",
    "    'IDfg',\n",
    "    'Name',\n",
    "    'Age',\n",
    "    'ERA',\n",
    "    'K/9',\n",
    "    'K/BB',\n",
    "    'AVG',\n",
    "    'WHIP',\n",
    "    'FIP',\n",
    "    'FB%',\n",
    "    'FBv',\n",
    "    'SL%',\n",
    "    'SLv',\n",
    "    'CT%',\n",
    "    'CTv',\n",
    "    'CB%',\n",
    "    'CBv',\n",
    "    'CH%',\n",
    "    'CHv',\n",
    "    'SF%',\n",
    "    'SFv',\n",
    "    'KN%',\n",
    "    'KNv',\n",
    "    'wFB/C',\n",
    "    'wSL/C',\n",
    "    'wCT/C',\n",
    "    'wCB/C',\n",
    "    'wCH/C',\n",
    "    'wSF/C',\n",
    "    'wKN/C',\n",
    "    'O-Swing%',\n",
    "    'Z-Swing%',\n",
    "    'Swing%',\n",
    "    'O-Contact%',\n",
    "    'Z-Contact%',\n",
    "    'Contact%',\n",
    "    'Zone%',\n",
    "    'F-Strike%',\n",
    "    'SwStr%',    \n",
    "]\n",
    "\n",
    "pitching_column_names_trimmed = [\n",
    "    'P_ERA',\n",
    "    'P_K/9',\n",
    "    'P_K/BB',\n",
    "    'P_AVG',\n",
    "    'P_WHIP',\n",
    "    'P_FIP',\n",
    "    'P_FB%',\n",
    "    'P_FBv',\n",
    "    'P_SL%',\n",
    "    'P_SLv',\n",
    "    'P_CT%',\n",
    "    'P_CTv',\n",
    "    'P_CB%',\n",
    "    'P_CBv',\n",
    "    'P_CH%',\n",
    "    'P_CHv',\n",
    "    'P_SF%',\n",
    "    'P_SFv',\n",
    "    'P_KN%',\n",
    "    'P_KNv',\n",
    "    'P_wFB/C',\n",
    "    'P_wSL/C',\n",
    "    'P_wCT/C',\n",
    "    'P_wCB/C',\n",
    "    'P_wCH/C',\n",
    "    'P_wSF/C',\n",
    "    'P_wKN/C',\n",
    "    'P_O-Swing%',\n",
    "    'P_Z-Swing%',\n",
    "    'P_Swing%',\n",
    "    'P_O-Contact%',\n",
    "    'P_Z-Contact%',\n",
    "    'P_Contact%',\n",
    "    'P_Zone%',\n",
    "    'P_F-Strike%',\n",
    "    'P_SwStr%',\n",
    "    'P_mlb_id'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {columns[i]:column_names[i] for i in range(len(columns))}\n",
    "\n",
    "game_logs = pd.DataFrame(columns=column_names)\n",
    "for year in years:\n",
    "    if year != '2020':\n",
    "        game_log_df = pd.read_csv('gl'+year+'.txt', header=None)\n",
    "        game_log_df.drop(game_log_df.columns.difference(columns),1,inplace=True)\n",
    "        game_log_df = game_log_df.rename(columns=x)\n",
    "\n",
    "        game_logs = pd.concat([game_logs,game_log_df],ignore_index=True)\n",
    "\n",
    "# add lineup_column_names to game_logs\n",
    "for col in lineup_column_names:\n",
    "    game_logs[col] = np.nan\n",
    "game_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of game_logs\n",
    "game_logs_home_p = game_logs.copy()\n",
    "game_logs_away_p = game_logs.copy()\n",
    "\n",
    "game_logs_home_p.drop(columns=['SP ID (Away)','SP Name (Away)','P1 ID (Home)','P2 ID (Home)', \\\n",
    "                               'P3 ID (Home)','P4 ID (Home)','P5 ID (Home)','P6 ID (Home)', \\\n",
    "                                'P7 ID (Home)','P8 ID (Home)','P9 ID (Home)'],inplace=True)\n",
    "\n",
    "game_logs_away_p.drop(columns=['SP ID (Home)','SP Name (Home)','P1 ID (Away)','P2 ID (Away)', \\\n",
    "                                'P3 ID (Away)','P4 ID (Away)','P5 ID (Away)','P6 ID (Away)', \\\n",
    "                                'P7 ID (Away)','P8 ID (Away)','P9 ID (Away)'],inplace=True)\n",
    "game_logs_home_p['mlb_id'] = np.nan\n",
    "game_logs_away_p['mlb_id'] = np.nan\n",
    "game_logs_away_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybaseball import batting_stats\n",
    "\n",
    "get_batting_stats = False\n",
    "if get_batting_stats:\n",
    "    # get batting_stats for each year between 2015 and 2023\n",
    "    for year in range(2015,2024):\n",
    "        bs = batting_stats(year, qual=50)\n",
    "        bs = bs.loc[:,lineup_column_names[1:]]\n",
    "        bs.to_csv(f'bs{year}.csv')\n",
    "\n",
    "    # create another set of csv files that have the average between two consecutive years\n",
    "    for year in range(2014,2022):\n",
    "        bs = batting_stats(year, year+1, qual=50, ind=0)\n",
    "        bs = bs.loc[:,lineup_column_names[1:]]\n",
    "        bs.to_csv(f'bs{year}-{year+1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pitching stats for each year between 2015 and 2023\n",
    "from pybaseball import pitching_stats\n",
    "\n",
    "get_pitching_stats = False\n",
    "if get_pitching_stats:\n",
    "    for year in range(2015,2023):\n",
    "        if year != 2020:\n",
    "            ps = pitching_stats(year, qual=50)\n",
    "            ps = ps.loc[:,pitching_column_names]\n",
    "            ps.to_csv(f'ps{year}.csv')\n",
    "\n",
    "    # create another set of csv files that have the average between two consecutive years\n",
    "    for year in range(2014,2022):\n",
    "        if year != 2021:\n",
    "            ps = pitching_stats(year, year+1, qual=50, ind=0)\n",
    "            ps = ps.loc[:,pitching_column_names]\n",
    "            ps.to_csv(f'ps{year}-{year+1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybaseball import playerid_lookup\n",
    "from pybaseball.lahman import *\n",
    "from pybaseball import playerid_reverse_lookup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_start_date(end_date):\n",
    "    # convert end_date to datetime object (it's of the form 'YYYYMMDD')\n",
    "    end_date = datetime.strptime(end_date, '%Y%m%d')\n",
    "    # subtract 100 days from end date to get start date (assume end_date is datetime object)\n",
    "    start_date = end_date - timedelta(days=100)\n",
    "\n",
    "    # if start_date is earlier in year than March 1, then take the difference and subtract that from September 30 of the previous year\n",
    "    if start_date.month < 3 or start_date.year < end_date.year:\n",
    "        day_diff = datetime(start_date.year, 3, 1) - start_date\n",
    "        start_date = datetime(start_date.year-1, 9, 30) - day_diff\n",
    "\n",
    "    return start_date, end_date\n",
    "\n",
    "def get_player_info(retroid):\n",
    "    player = playerid_reverse_lookup(retroid, key_type='retro')\n",
    "    player.fg_id = player['key_fangraphs'].values[0]\n",
    "    player.mlb_id = player['key_mlbam'].values[0]\n",
    "    player.fg_name = player['name_first'].values[0] + '-' + player['name_last'].values[0]\n",
    "    # if player.fg_name has any spaces, replace them with dashes\n",
    "    player.fg_name = player.fg_name.replace(' ', '-')\n",
    "    return player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "      <th>key_mlbam</th>\n",
       "      <th>key_retro</th>\n",
       "      <th>key_bbref</th>\n",
       "      <th>key_fangraphs</th>\n",
       "      <th>mlb_played_first</th>\n",
       "      <th>mlb_played_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wojciechowski</td>\n",
       "      <td>asher</td>\n",
       "      <td>592879</td>\n",
       "      <td>wojca001</td>\n",
       "      <td>wojcias01</td>\n",
       "      <td>10836</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_last name_first  key_mlbam key_retro  key_bbref  key_fangraphs  \\\n",
       "0  wojciechowski      asher     592879  wojca001  wojcias01          10836   \n",
       "\n",
       "   mlb_played_first  mlb_played_last  \n",
       "0            2015.0           2021.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = get_player_info(['wojca001'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in game_logs.iterrows():\n",
    "    print(index)\n",
    "\n",
    "    start_date, end_date = get_start_date(str(row['Date']))\n",
    "    lineup_home_df = pd.DataFrame(columns=lineup_column_names)\n",
    "    lineup_away_df = pd.DataFrame(columns=lineup_column_names)\n",
    "\n",
    "    if end_date.month < 4:\n",
    "        # load bs csv as df from previous year\n",
    "        bs_df = pd.read_csv(f'bs{end_date.year-1}.csv')\n",
    "        if end_date.year == 2021: # Don't have pitch data for 2020\n",
    "            ps_df = pd.read_csv(f'ps{end_date.year-1}-{end_date.year}.csv')\n",
    "        else:\n",
    "            ps_df = pd.read_csv(f'ps{end_date.year-1}.csv')\n",
    "    elif end_date.month > 3 and end_date.month < 6:\n",
    "        # load bs csv as df that spans two years\n",
    "        bs_df = pd.read_csv(f'bs{end_date.year-1}-{end_date.year}.csv')\n",
    "        ps_df = pd.read_csv(f'ps{end_date.year-1}-{end_date.year}.csv')\n",
    "    else:\n",
    "        # load bs csv as df from same year\n",
    "        bs_df = pd.read_csv(f'bs{end_date.year}.csv')\n",
    "        ps_df = pd.read_csv(f'ps{end_date.year}.csv')\n",
    "    # Add mlb id column to the ps_df and just make it NaN for now\n",
    "    ps_df['mlb_id'] = np.nan\n",
    "\n",
    "    for i in range(1,10):\n",
    "        home_player = get_player_info(row[[f'P{i} ID (Home)']])\n",
    "        away_player = get_player_info(row[[f'P{i} ID (Away)']])\n",
    "        # get the home_player stats from the bs_df\n",
    "        home_player_bs = bs_df.loc[bs_df['IDfg'] == home_player.fg_id]\n",
    "        lineup_home_df = pd.concat([lineup_home_df, home_player_bs], ignore_index=True)\n",
    "        # get the away_player stats from the bs_df\n",
    "        away_player_bs = bs_df.loc[bs_df['IDfg'] == away_player.fg_id]\n",
    "        lineup_away_df = pd.concat([lineup_away_df, away_player_bs], ignore_index=True)\n",
    "    \n",
    "    home_pitcher = get_player_info(row[['SP ID (Home)']])\n",
    "    away_pitcher = get_player_info(row[['SP ID (Away)']])\n",
    "    # get the away_pitcher stats from the ps_df\n",
    "    # if away_pitcher_fg_id exists in ps_df, then get the stats, else fill away_pitcher_ps with NaNs\n",
    "    if away_pitcher.fg_id in ps_df['IDfg'].values:\n",
    "        away_pitcher_ps = ps_df.loc[ps_df['IDfg'] == away_pitcher.fg_id]\n",
    "        away_pitcher_ps = away_pitcher_ps.copy()\n",
    "        away_pitcher_ps['mlb_id'] = int(away_pitcher.mlb_id)\n",
    "    else:\n",
    "        away_pitcher_ps = pd.DataFrame(np.nan, index=[0], columns=ps_df.columns)\n",
    "    \n",
    "    # Do same for home pitcher\n",
    "    if home_pitcher.fg_id in ps_df['IDfg'].values:\n",
    "        home_pitcher_ps = ps_df.loc[ps_df['IDfg'] == home_pitcher.fg_id]\n",
    "        home_pitcher_ps = home_pitcher_ps.copy()\n",
    "        home_pitcher_ps['mlb_id'] = int(home_pitcher.mlb_id)\n",
    "    else:\n",
    "        home_pitcher_ps = pd.DataFrame(np.nan, index=[0], columns=ps_df.columns)\n",
    "\n",
    "    # Add 'P_' prefix to each column name for pitcher_ps\n",
    "    away_pitcher_ps.columns = ['P_' + str(col) for col in away_pitcher_ps.columns]\n",
    "    home_pitcher_ps.columns = ['P_' + str(col) for col in home_pitcher_ps.columns]\n",
    "\n",
    "    if index == 10 or index == 100 or index == 800 or index == 1500:\n",
    "        lineup_home_df.to_csv(f'lineup_home_df_test{index}.csv')\n",
    "        away_pitcher_ps.to_csv(f'away_pitcher_ps_test{index}.csv')\n",
    "    \n",
    "    lineup_home_df = lineup_home_df.copy()\n",
    "    lineup_away_df = lineup_away_df.copy()\n",
    "    away_pitcher_ps = away_pitcher_ps.copy()\n",
    "    home_pitcher_ps = home_pitcher_ps.copy()\n",
    "    lineup_home_df.drop(columns=['Unnamed: 0','IDfg','Name','Age','PA'], inplace=True)\n",
    "    lineup_away_df.drop(columns=['Unnamed: 0','IDfg','Name','Age','PA'], inplace=True)\n",
    "    away_pitcher_ps.drop(columns=['P_Unnamed: 0','P_IDfg','P_Name','P_Age'], inplace=True)\n",
    "    home_pitcher_ps.drop(columns=['P_Unnamed: 0','P_IDfg','P_Name','P_Age'], inplace=True)\n",
    "    # Average all the stats in the lineup dataframe into one row\n",
    "    lineup_home_df = lineup_home_df.mean(axis=0)\n",
    "    lineup_away_df = lineup_away_df.mean(axis=0)\n",
    "\n",
    "    if index == 10 or index == 100 or index == 800 or index == 1500:\n",
    "        lineup_home_df.to_csv(f'lineup_df_home_average_test{index}.csv')\n",
    "        away_pitcher_ps.to_csv(f'away_pitcher_ps_average_test{index}.csv')\n",
    "\n",
    "\n",
    "    # Add the data to the current game log row\n",
    "    for col in lineup_column_names_trimmed:\n",
    "        game_logs_away_p.at[index, col] = lineup_home_df[col]\n",
    "        game_logs_home_p.at[index, col] = lineup_away_df[col]\n",
    "    for col in pitching_column_names_trimmed:\n",
    "        game_logs_away_p.at[index, col] = away_pitcher_ps[col].values[0]\n",
    "        game_logs_home_p.at[index, col] = home_pitcher_ps[col].values[0]\n",
    "\n",
    "game_logs_away_p.to_csv('game_logs_away_p.csv')\n",
    "game_logs_home_p.to_csv('game_logs_home_p.csv')\n",
    "game_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_logs.to_csv('game_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_logs_home_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name_mapping = {\n",
    "    'SLN': 'St. Louis',\n",
    "    'NYN': 'New York',\n",
    "    'SFN': 'San Francisco',\n",
    "    'LAN': 'Los Angeles',\n",
    "    'PHI': 'Philadelphia',\n",
    "    'ATL': 'Atlanta',\n",
    "    'MIL': 'Milwaukee',\n",
    "    'CIN': 'Cincinnati',\n",
    "    'PIT': 'Pittsburgh',\n",
    "    'SDN': 'San Diego',\n",
    "    'COL': 'Colorado',\n",
    "    'WAS': 'Washington',\n",
    "    'MIA': 'Miami',\n",
    "    'CHN': 'Chicago',\n",
    "    'ARI': 'Arizona',\n",
    "    'HOU': 'Houston',\n",
    "    'BOS': 'Boston',\n",
    "    'CHA': 'Chicago',\n",
    "    'NYA': 'New York',\n",
    "    'TBA': 'Tampa Bay',\n",
    "    'MIN': 'Minnesota',\n",
    "    'CLE': 'Cleveland',\n",
    "    'OAK': 'Oakland',\n",
    "    'TEX': 'Texas',\n",
    "    'TOR': 'Toronto',\n",
    "    'BAL': 'Baltimore',\n",
    "    'DET': 'Detroit',\n",
    "    'KCA': 'Kansas City',\n",
    "    'SEA': 'Seattle',\n",
    "    'ANA': 'Los Angeles'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_logs_home_p = pd.read_csv('game_logs_home_p.csv')\n",
    "game_logs_away_p = pd.read_csv('game_logs_away_p.csv')\n",
    "game_logs = pd.read_csv('game_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(game_logs_away_p.loc[110, 'P_mlb_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybaseball import pitching_stats_range\n",
    "import time\n",
    "# for each row in the game_logs dataframe, get the strikeouts of the starting away pitcher for the game\n",
    "game_logs_away_p = game_logs_away_p.copy()\n",
    "game_logs_home_p = game_logs_home_p.copy()\n",
    "game_logs_away_p['SP SO (Away)'] = np.nan\n",
    "game_logs_home_p['SP SO (Home)'] = np.nan\n",
    "\n",
    "last_day = 0\n",
    "for (index1, row1), (index2, row2) in zip(game_logs_away_p.iterrows(), game_logs_home_p.iterrows()):\n",
    "    print(index1)\n",
    "    date = str(row1['Date'])\n",
    "    # make date in the form YYYY-MM-DD\n",
    "    date = date[0:4] + '-' + date[4:6] + '-' + date[6:8]\n",
    "    # get the away pitcher's name\n",
    "    if not np.isnan(row1['P_mlb_id']) and not np.isnan(row2['P_mlb_id']):\n",
    "        away_pitcher_mlb_id = str(int(row1['P_mlb_id']))\n",
    "        home_pitcher_mlb_id = str(int(row2['P_mlb_id']))\n",
    "\n",
    "        # get the pitching stats from the start_date to the end_date\n",
    "        # turn date into datetime object\n",
    "        date_dt = datetime.strptime(date, '%Y-%m-%d')\n",
    "        print(date)\n",
    "        if date_dt.day != last_day:\n",
    "            # sleep for 1 seconds to avoid getting blocked by the server\n",
    "            time.sleep(1)\n",
    "            print('getting new stats')\n",
    "            pitcher_stats = pitching_stats_range(date,)\n",
    "        \n",
    "        last_day = date_dt.day\n",
    "\n",
    "        away_pitcher_game_stats = pitcher_stats.loc[pitcher_stats['mlbID'] == away_pitcher_mlb_id]\n",
    "        home_pitcher_game_stats = pitcher_stats.loc[pitcher_stats['mlbID'] == home_pitcher_mlb_id]\n",
    "\n",
    "        # check if away_pitcher_mlb_id is in the pitcher_stats['mlbID'] column\n",
    "        if not away_pitcher_game_stats.empty and not home_pitcher_game_stats.empty:\n",
    "            # get the pitcher's strikeouts for the game\n",
    "            away_pitcher_strikeouts = away_pitcher_game_stats['SO']\n",
    "            home_pitcher_strikeouts = home_pitcher_game_stats['SO']\n",
    "\n",
    "            # add the away pitcher's strikeouts to the game_logs dataframe\n",
    "            game_logs_away_p.at[index1, 'SP SO (Away)'] = away_pitcher_strikeouts\n",
    "            game_logs_home_p.at[index2, 'SP SO (Home)'] = home_pitcher_strikeouts\n",
    "        else:\n",
    "            print('pitcher not found with mlb_id: ' + away_pitcher_mlb_id + ' or ' + home_pitcher_mlb_id)\n",
    "\n",
    "    # if index1 is multiple of 500, save the game_logs dataframe to a csv\n",
    "    if index1 % 500 == 0:\n",
    "        game_logs_away_p.to_csv('game_logs_away_p.csv')\n",
    "        game_logs_home_p.to_csv('game_logs_home_p.csv')\n",
    "\n",
    "game_logs_away_p.to_csv('game_logs_away_p.csv')\n",
    "game_logs_home_p.to_csv('game_logs_home_p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_stats = pitching_stats_range('2022-10-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_stats.to_csv('pitcher_stats_20221005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = game_logs_home_p.copy()\n",
    "# append game_logs_away_p to dataset\n",
    "dataset = dataset.append(game_logs_away_p, ignore_index=True)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Unnamed: 0.2', 'Unnamed: 0.1','Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_home_p = game_logs_home_p.copy()\n",
    "dataset_away_p = game_logs_away_p.copy()\n",
    "dataset.to_csv('dataset_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_away_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_away_p.drop(columns=['Unnamed: 0.2', 'Unnamed: 0.1','Unnamed: 0','SO (Away)','SO (Home)'], inplace=True)\n",
    "dataset_away_p.rename(columns={'P1 ID (Home)': 'P1 ID', 'P2 ID (Home)': 'P2 ID', 'P3 ID (Home)': 'P3 ID', 'P4 ID (Home)': 'P4 ID',\\\n",
    "                               'P5 ID (Home)': 'P5 ID', 'P6 ID (Home)': 'P6 ID', 'P7 ID (Home)': 'P7 ID', 'P8 ID (Home)': 'P8 ID', \\\n",
    "                               'P9 ID (Home)': 'P9 ID','SP SO (Away)':'SP SO','SP ID (Away)': 'SP ID', 'SP Name (Away)':'SP Name'}, inplace=True)\n",
    "dataset_home_p.drop(columns=['Unnamed: 0.2', 'Unnamed: 0.1','Unnamed: 0','SO (Away)','SO (Home)'], inplace=True)\n",
    "dataset_home_p.rename(columns={'P1 ID (Away)': 'P1 ID', 'P2 ID (Away)': 'P2 ID', 'P3 ID (Away)': 'P3 ID', 'P4 ID (Away)': 'P4 ID',\\\n",
    "                               'P5 ID (Away)': 'P5 ID', 'P6 ID (Away)': 'P6 ID', 'P7 ID (Away)': 'P7 ID', 'P8 ID (Away)': 'P8 ID', \\\n",
    "                               'P9 ID (Away)': 'P9 ID','SP SO (Home)':'SP SO','SP ID (Home)': 'SP ID', 'SP Name (Home)':'SP Name'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean = dataset_home_p.copy()\n",
    "dataset_clean = dataset_clean.append(dataset_away_p, ignore_index=True)\n",
    "dataset_clean.drop(columns=['IDfg','Name','Age','PA'], inplace=True)\n",
    "dataset_clean.to_csv('dataset_clean.csv')\n",
    "dataset_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
